{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf,lit, desc, col, when, max\n",
    "from functools import reduce\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.linalg import Vectors, SparseVector, DenseVector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title(s):\n",
    "    print(\"---- %s -----\" %s)    \n",
    "    \n",
    "def see(s, v):\n",
    "    print(\"---- %s -----\" %s)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 OneHot encoding for \"sales\" and \"salary\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = \"../data/HR_comma_sep.csv\"\n",
    "rawDF = spark.read.csv(files, header=True, inferSchema=True)\n",
    "stages=[]\n",
    "categoricalColumns = [\"sales\", \"salary\"]\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + \"Index\")\n",
    "    encoder = OneHotEncoder(inputCol=categoricalCol + \"Index\", outputCol=categoricalCol + \"Vec\")\n",
    "    stages += [stringIndexer, encoder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages\n",
    "rawDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Convert label into label indices using the StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stringIdx = StringIndexer(inputCol = \"left\", outputCol = \"label\")\n",
    "stages += [label_stringIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Transform all features into a vector using VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericCols = [\"satisfaction_level\",\\\n",
    "               \"last_evaluation\",\\\n",
    "               \"number_project\",\\\n",
    "               \"average_montly_hours\",\\\n",
    "               \"time_spend_company\",\\\n",
    "               \"Work_accident\",\\\n",
    "              \"promotion_last_5years\"]\n",
    "assemblerInputs = numericCols + list(map(lambda c: c + \"Vec\", categoricalColumns))\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Create a Pipeline, Fit and Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=stages)\n",
    "pipelineModel = pipeline.fit(rawDF)\n",
    "rawDF = pipelineModel.transform(rawDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Keep relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedcols = [\"label\", \"features\"]\n",
    "rawDF = rawDF.select(selectedcols)\n",
    "rawDF = rawDF.rdd.map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  SparseVector(18, {0: 0.38, 1: 0.53, 2: 2.0, 3: 157.0, 4: 3.0, 7: 1.0, 16: 1.0})]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display(rawDF)\n",
    "rawDF.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 convert Sparse vectors to DenseVectors and have LabeledPoints set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(elem):\n",
    "    label = elem[0]\n",
    "    featureVector = Vectors.dense(elem[1])\n",
    "    return LabeledPoint(label, featureVector)\n",
    "\n",
    "data = rawDF.map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [0.38,0.53,2.0,157.0,3.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.8,0.86,5.0,262.0,6.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [0.11,0.88,7.0,272.0,4.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]),\n",
       " LabeledPoint(1.0, [0.72,0.87,5.0,223.0,5.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.37,0.52,2.0,159.0,3.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.41,0.5,2.0,153.0,3.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.1,0.77,6.0,247.0,4.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.92,0.85,5.0,259.0,5.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.89,1.0,5.0,224.0,5.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]),\n",
       " LabeledPoint(1.0, [0.42,0.53,2.0,142.0,3.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Split the data into 3 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- data -----\n",
      "14999\n",
      "---- sampledData -----\n",
      "754\n"
     ]
    }
   ],
   "source": [
    "see(\"data\", data.count())\n",
    "sampledData = data.sample(fraction=0.05, withReplacement=False, seed=17)\n",
    "\n",
    "see(\"sampledData\", sampledData.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(1.0, [0.38,0.46,2.0,137.0,3.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampledData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[43] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainData, cvData, testData) = data.randomSplit(weights=[0.8, 0.1, 0.1])\n",
    "#(trainData, cvData, testData) = sampledData.randomSplit(weights=[0.8, 0.1, 0.1])\n",
    "trainData.cache()\n",
    "cvData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Building a decison tree classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 7.15 s\n"
     ]
    }
   ],
   "source": [
    "def buildDecisionTreeClassifier(trainData):\n",
    "    model = DecisionTree.trainClassifier(trainData,numClasses=2,\\\n",
    "                                         categoricalFeaturesInfo={},\\\n",
    "                                         impurity=\"gini\",\\\n",
    "                                         maxDepth=4,\\\n",
    "                                         maxBins=100)\n",
    "    return  model\n",
    "%time m1 =  buildDecisionTreeClassifier(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeModel classifier of depth 4 with 27 nodes"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Testing the trained model (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- testPoint -----\n",
      "(1.0,[0.11,0.88,7.0,272.0,4.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0])\n",
      "---- label -----\n",
      "1.0\n",
      "---- features -----\n",
      "[0.11,0.88,7.0,272.0,4.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]\n"
     ]
    }
   ],
   "source": [
    "testPoint = testData.first()\n",
    "see(\"testPoint\", testPoint)\n",
    "\n",
    "label = testPoint.label\n",
    "see(\"label\", label)\n",
    "\n",
    "features = testPoint.features\n",
    "see(\"features\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- predictedLabel -----\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "predictedLabel = m1.predict(testPoint.features)\n",
    "see(\"predictedLabel\", predictedLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 0.0, correct: False\n",
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 1.0, correct: True\n",
      "label: 1.0 , predicted: 0.0, correct: False\n"
     ]
    }
   ],
   "source": [
    "testPoints = testData.take(10)\n",
    "for testPoint in testPoints:\n",
    "    label = testPoint.label\n",
    "    predictedLabel = m1.predict(testPoint.features)\n",
    "    print(\"label: %s , predicted: %s, correct: %s\"  %(label,predictedLabel, label==predictedLabel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Evaluate the model using the Accuracy metric in SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Caclusating the metrics using Spark Mulitclass\n",
    "def getMetrics(model, data):\n",
    "    labels = data.map(lambda d: d.label)\n",
    "    features = data.map(lambda d: d.features)\n",
    "    predictions = model.predict(features)\n",
    "    predictionsAndLabels = predictions.zip(labels)\n",
    "    return MulticlassMetrics(predictionsAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.73 s\n",
      "---- accuracy -----\n",
      "0.966042966042966\n"
     ]
    }
   ],
   "source": [
    "metrics = getMetrics(m1, cvData)\n",
    "%time accuracy = metrics.accuracy\n",
    "see(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Tuning HyperParams using CVData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Trying combinations of hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('gini', 1, 10), 0.7657657657657657),\n",
       " (('gini', 1, 300), 0.7914067914067914),\n",
       " (('gini', 20, 10), 0.9653499653499653),\n",
       " (('gini', 20, 300), 0.9715869715869716),\n",
       " (('entropy', 1, 10), 0.7657657657657657),\n",
       " (('entropy', 1, 300), 0.7914067914067914),\n",
       " (('entropy', 20, 10), 0.9702009702009702),\n",
       " (('entropy', 20, 300), 0.972972972972973)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(trainData, cvData):\n",
    "    evaluations = []\n",
    "    #Take combinations of 3 hyperparams, evaluating the accuracy of each using CV Dataset\n",
    "    for impurity in [\"gini\", \"entropy\"]:\n",
    "        for depth in [1, 20]:\n",
    "            for bins in [10, 300]:\n",
    "                model = DecisionTree.trainClassifier(trainData,numClasses=2, categoricalFeaturesInfo={}, impurity=impurity, maxDepth=depth, maxBins=bins)\n",
    "                accuracy = getMetrics(model, cvData).accuracy\n",
    "                evaluations.append(((impurity, depth, bins), accuracy))\n",
    "\n",
    "    return evaluations\n",
    "evaluations = evaluate(trainData, cvData)\n",
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Sorted Evaluations -----\n",
      "(('entropy', 20, 300), 0.972972972972973)\n",
      "(('gini', 20, 300), 0.9715869715869716)\n",
      "(('entropy', 20, 10), 0.9702009702009702)\n",
      "(('gini', 20, 10), 0.9653499653499653)\n",
      "(('gini', 1, 300), 0.7914067914067914)\n",
      "(('entropy', 1, 300), 0.7914067914067914)\n",
      "(('gini', 1, 10), 0.7657657657657657)\n",
      "(('entropy', 1, 10), 0.7657657657657657)\n"
     ]
    }
   ],
   "source": [
    "sortedEvals = sorted(evaluations, key=lambda a:a[1], reverse=True)\n",
    "title(\"Sorted Evaluations\")\n",
    "for e in sortedEvals:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- bestParams -----\n",
      "('entropy', 20, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestParams = sortedEvals[0][0]\n",
    "see(\"bestParams\", bestParams)\n",
    "type(bestParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6: Evaluate best hyper params using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- testData accuracy -----\n",
      "0.9864253393665159\n",
      "---- testData+cvData accuracy -----\n",
      "0.9929765886287626\n"
     ]
    }
   ],
   "source": [
    "(i, d, b) = bestParams\n",
    "model = DecisionTree.trainClassifier(\n",
    "    trainData.union(cvData),\n",
    "    numClasses=2, \n",
    "    categoricalFeaturesInfo={}, \n",
    "    impurity=i, \n",
    "    maxDepth=d, \n",
    "    maxBins=b)\n",
    "see(\"testData accuracy\",getMetrics(model, testData).accuracy)\n",
    "see(\"testData+cvData accuracy\", getMetrics(model, testData.union(cvData)).accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up persisted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[43] at RDD at PythonRDD.scala:48"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.unpersist()\n",
    "cvData.unpersist()\n",
    "testData.unpersist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
